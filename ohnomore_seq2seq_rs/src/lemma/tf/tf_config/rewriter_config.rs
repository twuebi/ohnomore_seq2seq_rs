// This file is generated by rust-protobuf 2.0.4. Do not edit
// @generated

// https://github.com/Manishearth/rust-clippy/issues/702
#![allow(unknown_lints)]
#![allow(clippy)]

#![cfg_attr(rustfmt, rustfmt_skip)]

#![allow(box_pointers)]
#![allow(dead_code)]
#![allow(missing_docs)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(trivial_casts)]
#![allow(unsafe_code)]
#![allow(unused_imports)]
#![allow(unused_results)]

use protobuf::Message as Message_imported_for_functions;
use protobuf::ProtobufEnum as ProtobufEnum_imported_for_functions;

#[derive(PartialEq,Clone,Default)]
pub struct AutoParallelOptions {
    // message fields
    pub enable: bool,
    pub num_replicas: i32,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl AutoParallelOptions {
    pub fn new() -> AutoParallelOptions {
        ::std::default::Default::default()
    }

    // bool enable = 1;

    pub fn clear_enable(&mut self) {
        self.enable = false;
    }

    // Param is passed by value, moved
    pub fn set_enable(&mut self, v: bool) {
        self.enable = v;
    }

    pub fn get_enable(&self) -> bool {
        self.enable
    }

    // int32 num_replicas = 2;

    pub fn clear_num_replicas(&mut self) {
        self.num_replicas = 0;
    }

    // Param is passed by value, moved
    pub fn set_num_replicas(&mut self, v: i32) {
        self.num_replicas = v;
    }

    pub fn get_num_replicas(&self) -> i32 {
        self.num_replicas
    }
}

impl ::protobuf::Message for AutoParallelOptions {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.enable = tmp;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.num_replicas = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if self.enable != false {
            my_size += 2;
        }
        if self.num_replicas != 0 {
            my_size += ::protobuf::rt::value_size(2, self.num_replicas, ::protobuf::wire_format::WireTypeVarint);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        if self.enable != false {
            os.write_bool(1, self.enable)?;
        }
        if self.num_replicas != 0 {
            os.write_int32(2, self.num_replicas)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> AutoParallelOptions {
        AutoParallelOptions::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                    "enable",
                    |m: &AutoParallelOptions| { &m.enable },
                    |m: &mut AutoParallelOptions| { &mut m.enable },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                    "num_replicas",
                    |m: &AutoParallelOptions| { &m.num_replicas },
                    |m: &mut AutoParallelOptions| { &mut m.num_replicas },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<AutoParallelOptions>(
                    "AutoParallelOptions",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static AutoParallelOptions {
        static mut instance: ::protobuf::lazy::Lazy<AutoParallelOptions> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const AutoParallelOptions,
        };
        unsafe {
            instance.get(AutoParallelOptions::new)
        }
    }
}

impl ::protobuf::Clear for AutoParallelOptions {
    fn clear(&mut self) {
        self.clear_enable();
        self.clear_num_replicas();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for AutoParallelOptions {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for AutoParallelOptions {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct ScopedAllocatorOptions {
    // message fields
    pub enable_op: ::protobuf::RepeatedField<::std::string::String>,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl ScopedAllocatorOptions {
    pub fn new() -> ScopedAllocatorOptions {
        ::std::default::Default::default()
    }

    // repeated string enable_op = 1;

    pub fn clear_enable_op(&mut self) {
        self.enable_op.clear();
    }

    // Param is passed by value, moved
    pub fn set_enable_op(&mut self, v: ::protobuf::RepeatedField<::std::string::String>) {
        self.enable_op = v;
    }

    // Mutable pointer to the field.
    pub fn mut_enable_op(&mut self) -> &mut ::protobuf::RepeatedField<::std::string::String> {
        &mut self.enable_op
    }

    // Take field
    pub fn take_enable_op(&mut self) -> ::protobuf::RepeatedField<::std::string::String> {
        ::std::mem::replace(&mut self.enable_op, ::protobuf::RepeatedField::new())
    }

    pub fn get_enable_op(&self) -> &[::std::string::String] {
        &self.enable_op
    }
}

impl ::protobuf::Message for ScopedAllocatorOptions {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_repeated_string_into(wire_type, is, &mut self.enable_op)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.enable_op {
            my_size += ::protobuf::rt::string_size(1, &value);
        };
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        for v in &self.enable_op {
            os.write_string(1, &v)?;
        };
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> ScopedAllocatorOptions {
        ScopedAllocatorOptions::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                    "enable_op",
                    |m: &ScopedAllocatorOptions| { &m.enable_op },
                    |m: &mut ScopedAllocatorOptions| { &mut m.enable_op },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<ScopedAllocatorOptions>(
                    "ScopedAllocatorOptions",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static ScopedAllocatorOptions {
        static mut instance: ::protobuf::lazy::Lazy<ScopedAllocatorOptions> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ScopedAllocatorOptions,
        };
        unsafe {
            instance.get(ScopedAllocatorOptions::new)
        }
    }
}

impl ::protobuf::Clear for ScopedAllocatorOptions {
    fn clear(&mut self) {
        self.clear_enable_op();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for ScopedAllocatorOptions {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for ScopedAllocatorOptions {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct RewriterConfig {
    // message fields
    pub layout_optimizer: RewriterConfig_Toggle,
    pub constant_folding: RewriterConfig_Toggle,
    pub shape_optimization: RewriterConfig_Toggle,
    pub remapping: RewriterConfig_Toggle,
    pub arithmetic_optimization: RewriterConfig_Toggle,
    pub dependency_optimization: RewriterConfig_Toggle,
    pub loop_optimization: RewriterConfig_Toggle,
    pub function_optimization: RewriterConfig_Toggle,
    pub debug_stripper: RewriterConfig_Toggle,
    pub disable_model_pruning: bool,
    pub scoped_allocator_optimization: RewriterConfig_Toggle,
    pub meta_optimizer_iterations: RewriterConfig_NumIterationsType,
    pub min_graph_nodes: i32,
    pub memory_optimization: RewriterConfig_MemOptType,
    pub memory_optimizer_target_node_name_scope: ::std::string::String,
    pub auto_parallel: ::protobuf::SingularPtrField<AutoParallelOptions>,
    pub scoped_allocator_opts: ::protobuf::SingularPtrField<ScopedAllocatorOptions>,
    pub optimizers: ::protobuf::RepeatedField<::std::string::String>,
    pub custom_optimizers: ::protobuf::RepeatedField<RewriterConfig_CustomGraphOptimizer>,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl RewriterConfig {
    pub fn new() -> RewriterConfig {
        ::std::default::Default::default()
    }

    // .tensorflow.RewriterConfig.Toggle layout_optimizer = 1;

    pub fn clear_layout_optimizer(&mut self) {
        self.layout_optimizer = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_layout_optimizer(&mut self, v: RewriterConfig_Toggle) {
        self.layout_optimizer = v;
    }

    pub fn get_layout_optimizer(&self) -> RewriterConfig_Toggle {
        self.layout_optimizer
    }

    // .tensorflow.RewriterConfig.Toggle constant_folding = 3;

    pub fn clear_constant_folding(&mut self) {
        self.constant_folding = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_constant_folding(&mut self, v: RewriterConfig_Toggle) {
        self.constant_folding = v;
    }

    pub fn get_constant_folding(&self) -> RewriterConfig_Toggle {
        self.constant_folding
    }

    // .tensorflow.RewriterConfig.Toggle shape_optimization = 13;

    pub fn clear_shape_optimization(&mut self) {
        self.shape_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_shape_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.shape_optimization = v;
    }

    pub fn get_shape_optimization(&self) -> RewriterConfig_Toggle {
        self.shape_optimization
    }

    // .tensorflow.RewriterConfig.Toggle remapping = 14;

    pub fn clear_remapping(&mut self) {
        self.remapping = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_remapping(&mut self, v: RewriterConfig_Toggle) {
        self.remapping = v;
    }

    pub fn get_remapping(&self) -> RewriterConfig_Toggle {
        self.remapping
    }

    // .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;

    pub fn clear_arithmetic_optimization(&mut self) {
        self.arithmetic_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_arithmetic_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.arithmetic_optimization = v;
    }

    pub fn get_arithmetic_optimization(&self) -> RewriterConfig_Toggle {
        self.arithmetic_optimization
    }

    // .tensorflow.RewriterConfig.Toggle dependency_optimization = 8;

    pub fn clear_dependency_optimization(&mut self) {
        self.dependency_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_dependency_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.dependency_optimization = v;
    }

    pub fn get_dependency_optimization(&self) -> RewriterConfig_Toggle {
        self.dependency_optimization
    }

    // .tensorflow.RewriterConfig.Toggle loop_optimization = 9;

    pub fn clear_loop_optimization(&mut self) {
        self.loop_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_loop_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.loop_optimization = v;
    }

    pub fn get_loop_optimization(&self) -> RewriterConfig_Toggle {
        self.loop_optimization
    }

    // .tensorflow.RewriterConfig.Toggle function_optimization = 10;

    pub fn clear_function_optimization(&mut self) {
        self.function_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_function_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.function_optimization = v;
    }

    pub fn get_function_optimization(&self) -> RewriterConfig_Toggle {
        self.function_optimization
    }

    // .tensorflow.RewriterConfig.Toggle debug_stripper = 11;

    pub fn clear_debug_stripper(&mut self) {
        self.debug_stripper = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_debug_stripper(&mut self, v: RewriterConfig_Toggle) {
        self.debug_stripper = v;
    }

    pub fn get_debug_stripper(&self) -> RewriterConfig_Toggle {
        self.debug_stripper
    }

    // bool disable_model_pruning = 2;

    pub fn clear_disable_model_pruning(&mut self) {
        self.disable_model_pruning = false;
    }

    // Param is passed by value, moved
    pub fn set_disable_model_pruning(&mut self, v: bool) {
        self.disable_model_pruning = v;
    }

    pub fn get_disable_model_pruning(&self) -> bool {
        self.disable_model_pruning
    }

    // .tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;

    pub fn clear_scoped_allocator_optimization(&mut self) {
        self.scoped_allocator_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_scoped_allocator_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.scoped_allocator_optimization = v;
    }

    pub fn get_scoped_allocator_optimization(&self) -> RewriterConfig_Toggle {
        self.scoped_allocator_optimization
    }

    // .tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;

    pub fn clear_meta_optimizer_iterations(&mut self) {
        self.meta_optimizer_iterations = RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS;
    }

    // Param is passed by value, moved
    pub fn set_meta_optimizer_iterations(&mut self, v: RewriterConfig_NumIterationsType) {
        self.meta_optimizer_iterations = v;
    }

    pub fn get_meta_optimizer_iterations(&self) -> RewriterConfig_NumIterationsType {
        self.meta_optimizer_iterations
    }

    // int32 min_graph_nodes = 17;

    pub fn clear_min_graph_nodes(&mut self) {
        self.min_graph_nodes = 0;
    }

    // Param is passed by value, moved
    pub fn set_min_graph_nodes(&mut self, v: i32) {
        self.min_graph_nodes = v;
    }

    pub fn get_min_graph_nodes(&self) -> i32 {
        self.min_graph_nodes
    }

    // .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;

    pub fn clear_memory_optimization(&mut self) {
        self.memory_optimization = RewriterConfig_MemOptType::DEFAULT_MEM_OPT;
    }

    // Param is passed by value, moved
    pub fn set_memory_optimization(&mut self, v: RewriterConfig_MemOptType) {
        self.memory_optimization = v;
    }

    pub fn get_memory_optimization(&self) -> RewriterConfig_MemOptType {
        self.memory_optimization
    }

    // string memory_optimizer_target_node_name_scope = 6;

    pub fn clear_memory_optimizer_target_node_name_scope(&mut self) {
        self.memory_optimizer_target_node_name_scope.clear();
    }

    // Param is passed by value, moved
    pub fn set_memory_optimizer_target_node_name_scope(&mut self, v: ::std::string::String) {
        self.memory_optimizer_target_node_name_scope = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_memory_optimizer_target_node_name_scope(&mut self) -> &mut ::std::string::String {
        &mut self.memory_optimizer_target_node_name_scope
    }

    // Take field
    pub fn take_memory_optimizer_target_node_name_scope(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.memory_optimizer_target_node_name_scope, ::std::string::String::new())
    }

    pub fn get_memory_optimizer_target_node_name_scope(&self) -> &str {
        &self.memory_optimizer_target_node_name_scope
    }

    // .tensorflow.AutoParallelOptions auto_parallel = 5;

    pub fn clear_auto_parallel(&mut self) {
        self.auto_parallel.clear();
    }

    pub fn has_auto_parallel(&self) -> bool {
        self.auto_parallel.is_some()
    }

    // Param is passed by value, moved
    pub fn set_auto_parallel(&mut self, v: AutoParallelOptions) {
        self.auto_parallel = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_auto_parallel(&mut self) -> &mut AutoParallelOptions {
        if self.auto_parallel.is_none() {
            self.auto_parallel.set_default();
        }
        self.auto_parallel.as_mut().unwrap()
    }

    // Take field
    pub fn take_auto_parallel(&mut self) -> AutoParallelOptions {
        self.auto_parallel.take().unwrap_or_else(|| AutoParallelOptions::new())
    }

    pub fn get_auto_parallel(&self) -> &AutoParallelOptions {
        self.auto_parallel.as_ref().unwrap_or_else(|| AutoParallelOptions::default_instance())
    }

    // .tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;

    pub fn clear_scoped_allocator_opts(&mut self) {
        self.scoped_allocator_opts.clear();
    }

    pub fn has_scoped_allocator_opts(&self) -> bool {
        self.scoped_allocator_opts.is_some()
    }

    // Param is passed by value, moved
    pub fn set_scoped_allocator_opts(&mut self, v: ScopedAllocatorOptions) {
        self.scoped_allocator_opts = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_scoped_allocator_opts(&mut self) -> &mut ScopedAllocatorOptions {
        if self.scoped_allocator_opts.is_none() {
            self.scoped_allocator_opts.set_default();
        }
        self.scoped_allocator_opts.as_mut().unwrap()
    }

    // Take field
    pub fn take_scoped_allocator_opts(&mut self) -> ScopedAllocatorOptions {
        self.scoped_allocator_opts.take().unwrap_or_else(|| ScopedAllocatorOptions::new())
    }

    pub fn get_scoped_allocator_opts(&self) -> &ScopedAllocatorOptions {
        self.scoped_allocator_opts.as_ref().unwrap_or_else(|| ScopedAllocatorOptions::default_instance())
    }

    // repeated string optimizers = 100;

    pub fn clear_optimizers(&mut self) {
        self.optimizers.clear();
    }

    // Param is passed by value, moved
    pub fn set_optimizers(&mut self, v: ::protobuf::RepeatedField<::std::string::String>) {
        self.optimizers = v;
    }

    // Mutable pointer to the field.
    pub fn mut_optimizers(&mut self) -> &mut ::protobuf::RepeatedField<::std::string::String> {
        &mut self.optimizers
    }

    // Take field
    pub fn take_optimizers(&mut self) -> ::protobuf::RepeatedField<::std::string::String> {
        ::std::mem::replace(&mut self.optimizers, ::protobuf::RepeatedField::new())
    }

    pub fn get_optimizers(&self) -> &[::std::string::String] {
        &self.optimizers
    }

    // repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;

    pub fn clear_custom_optimizers(&mut self) {
        self.custom_optimizers.clear();
    }

    // Param is passed by value, moved
    pub fn set_custom_optimizers(&mut self, v: ::protobuf::RepeatedField<RewriterConfig_CustomGraphOptimizer>) {
        self.custom_optimizers = v;
    }

    // Mutable pointer to the field.
    pub fn mut_custom_optimizers(&mut self) -> &mut ::protobuf::RepeatedField<RewriterConfig_CustomGraphOptimizer> {
        &mut self.custom_optimizers
    }

    // Take field
    pub fn take_custom_optimizers(&mut self) -> ::protobuf::RepeatedField<RewriterConfig_CustomGraphOptimizer> {
        ::std::mem::replace(&mut self.custom_optimizers, ::protobuf::RepeatedField::new())
    }

    pub fn get_custom_optimizers(&self) -> &[RewriterConfig_CustomGraphOptimizer] {
        &self.custom_optimizers
    }
}

impl ::protobuf::Message for RewriterConfig {
    fn is_initialized(&self) -> bool {
        for v in &self.auto_parallel {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.scoped_allocator_opts {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.custom_optimizers {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.layout_optimizer, 1, &mut self.unknown_fields)?
                },
                3 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.constant_folding, 3, &mut self.unknown_fields)?
                },
                13 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.shape_optimization, 13, &mut self.unknown_fields)?
                },
                14 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.remapping, 14, &mut self.unknown_fields)?
                },
                7 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.arithmetic_optimization, 7, &mut self.unknown_fields)?
                },
                8 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.dependency_optimization, 8, &mut self.unknown_fields)?
                },
                9 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.loop_optimization, 9, &mut self.unknown_fields)?
                },
                10 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.function_optimization, 10, &mut self.unknown_fields)?
                },
                11 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.debug_stripper, 11, &mut self.unknown_fields)?
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.disable_model_pruning = tmp;
                },
                15 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.scoped_allocator_optimization, 15, &mut self.unknown_fields)?
                },
                12 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.meta_optimizer_iterations, 12, &mut self.unknown_fields)?
                },
                17 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.min_graph_nodes = tmp;
                },
                4 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.memory_optimization, 4, &mut self.unknown_fields)?
                },
                6 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.memory_optimizer_target_node_name_scope)?;
                },
                5 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.auto_parallel)?;
                },
                16 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.scoped_allocator_opts)?;
                },
                100 => {
                    ::protobuf::rt::read_repeated_string_into(wire_type, is, &mut self.optimizers)?;
                },
                200 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.custom_optimizers)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if self.layout_optimizer != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(1, self.layout_optimizer);
        }
        if self.constant_folding != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(3, self.constant_folding);
        }
        if self.shape_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(13, self.shape_optimization);
        }
        if self.remapping != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(14, self.remapping);
        }
        if self.arithmetic_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(7, self.arithmetic_optimization);
        }
        if self.dependency_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(8, self.dependency_optimization);
        }
        if self.loop_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(9, self.loop_optimization);
        }
        if self.function_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(10, self.function_optimization);
        }
        if self.debug_stripper != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(11, self.debug_stripper);
        }
        if self.disable_model_pruning != false {
            my_size += 2;
        }
        if self.scoped_allocator_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(15, self.scoped_allocator_optimization);
        }
        if self.meta_optimizer_iterations != RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS {
            my_size += ::protobuf::rt::enum_size(12, self.meta_optimizer_iterations);
        }
        if self.min_graph_nodes != 0 {
            my_size += ::protobuf::rt::value_size(17, self.min_graph_nodes, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.memory_optimization != RewriterConfig_MemOptType::DEFAULT_MEM_OPT {
            my_size += ::protobuf::rt::enum_size(4, self.memory_optimization);
        }
        if !self.memory_optimizer_target_node_name_scope.is_empty() {
            my_size += ::protobuf::rt::string_size(6, &self.memory_optimizer_target_node_name_scope);
        }
        if let Some(ref v) = self.auto_parallel.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if let Some(ref v) = self.scoped_allocator_opts.as_ref() {
            let len = v.compute_size();
            my_size += 2 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        for value in &self.optimizers {
            my_size += ::protobuf::rt::string_size(100, &value);
        };
        for value in &self.custom_optimizers {
            let len = value.compute_size();
            my_size += 2 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        if self.layout_optimizer != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(1, self.layout_optimizer.value())?;
        }
        if self.constant_folding != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(3, self.constant_folding.value())?;
        }
        if self.shape_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(13, self.shape_optimization.value())?;
        }
        if self.remapping != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(14, self.remapping.value())?;
        }
        if self.arithmetic_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(7, self.arithmetic_optimization.value())?;
        }
        if self.dependency_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(8, self.dependency_optimization.value())?;
        }
        if self.loop_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(9, self.loop_optimization.value())?;
        }
        if self.function_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(10, self.function_optimization.value())?;
        }
        if self.debug_stripper != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(11, self.debug_stripper.value())?;
        }
        if self.disable_model_pruning != false {
            os.write_bool(2, self.disable_model_pruning)?;
        }
        if self.scoped_allocator_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(15, self.scoped_allocator_optimization.value())?;
        }
        if self.meta_optimizer_iterations != RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS {
            os.write_enum(12, self.meta_optimizer_iterations.value())?;
        }
        if self.min_graph_nodes != 0 {
            os.write_int32(17, self.min_graph_nodes)?;
        }
        if self.memory_optimization != RewriterConfig_MemOptType::DEFAULT_MEM_OPT {
            os.write_enum(4, self.memory_optimization.value())?;
        }
        if !self.memory_optimizer_target_node_name_scope.is_empty() {
            os.write_string(6, &self.memory_optimizer_target_node_name_scope)?;
        }
        if let Some(ref v) = self.auto_parallel.as_ref() {
            os.write_tag(5, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if let Some(ref v) = self.scoped_allocator_opts.as_ref() {
            os.write_tag(16, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        for v in &self.optimizers {
            os.write_string(100, &v)?;
        };
        for v in &self.custom_optimizers {
            os.write_tag(200, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RewriterConfig {
        RewriterConfig::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "layout_optimizer",
                    |m: &RewriterConfig| { &m.layout_optimizer },
                    |m: &mut RewriterConfig| { &mut m.layout_optimizer },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "constant_folding",
                    |m: &RewriterConfig| { &m.constant_folding },
                    |m: &mut RewriterConfig| { &mut m.constant_folding },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "shape_optimization",
                    |m: &RewriterConfig| { &m.shape_optimization },
                    |m: &mut RewriterConfig| { &mut m.shape_optimization },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "remapping",
                    |m: &RewriterConfig| { &m.remapping },
                    |m: &mut RewriterConfig| { &mut m.remapping },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "arithmetic_optimization",
                    |m: &RewriterConfig| { &m.arithmetic_optimization },
                    |m: &mut RewriterConfig| { &mut m.arithmetic_optimization },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "dependency_optimization",
                    |m: &RewriterConfig| { &m.dependency_optimization },
                    |m: &mut RewriterConfig| { &mut m.dependency_optimization },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "loop_optimization",
                    |m: &RewriterConfig| { &m.loop_optimization },
                    |m: &mut RewriterConfig| { &mut m.loop_optimization },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "function_optimization",
                    |m: &RewriterConfig| { &m.function_optimization },
                    |m: &mut RewriterConfig| { &mut m.function_optimization },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "debug_stripper",
                    |m: &RewriterConfig| { &m.debug_stripper },
                    |m: &mut RewriterConfig| { &mut m.debug_stripper },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                    "disable_model_pruning",
                    |m: &RewriterConfig| { &m.disable_model_pruning },
                    |m: &mut RewriterConfig| { &mut m.disable_model_pruning },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                    "scoped_allocator_optimization",
                    |m: &RewriterConfig| { &m.scoped_allocator_optimization },
                    |m: &mut RewriterConfig| { &mut m.scoped_allocator_optimization },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_NumIterationsType>>(
                    "meta_optimizer_iterations",
                    |m: &RewriterConfig| { &m.meta_optimizer_iterations },
                    |m: &mut RewriterConfig| { &mut m.meta_optimizer_iterations },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                    "min_graph_nodes",
                    |m: &RewriterConfig| { &m.min_graph_nodes },
                    |m: &mut RewriterConfig| { &mut m.min_graph_nodes },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_MemOptType>>(
                    "memory_optimization",
                    |m: &RewriterConfig| { &m.memory_optimization },
                    |m: &mut RewriterConfig| { &mut m.memory_optimization },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                    "memory_optimizer_target_node_name_scope",
                    |m: &RewriterConfig| { &m.memory_optimizer_target_node_name_scope },
                    |m: &mut RewriterConfig| { &mut m.memory_optimizer_target_node_name_scope },
                ));
                fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<AutoParallelOptions>>(
                    "auto_parallel",
                    |m: &RewriterConfig| { &m.auto_parallel },
                    |m: &mut RewriterConfig| { &mut m.auto_parallel },
                ));
                fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<ScopedAllocatorOptions>>(
                    "scoped_allocator_opts",
                    |m: &RewriterConfig| { &m.scoped_allocator_opts },
                    |m: &mut RewriterConfig| { &mut m.scoped_allocator_opts },
                ));
                fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                    "optimizers",
                    |m: &RewriterConfig| { &m.optimizers },
                    |m: &mut RewriterConfig| { &mut m.optimizers },
                ));
                fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<RewriterConfig_CustomGraphOptimizer>>(
                    "custom_optimizers",
                    |m: &RewriterConfig| { &m.custom_optimizers },
                    |m: &mut RewriterConfig| { &mut m.custom_optimizers },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<RewriterConfig>(
                    "RewriterConfig",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static RewriterConfig {
        static mut instance: ::protobuf::lazy::Lazy<RewriterConfig> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const RewriterConfig,
        };
        unsafe {
            instance.get(RewriterConfig::new)
        }
    }
}

impl ::protobuf::Clear for RewriterConfig {
    fn clear(&mut self) {
        self.clear_layout_optimizer();
        self.clear_constant_folding();
        self.clear_shape_optimization();
        self.clear_remapping();
        self.clear_arithmetic_optimization();
        self.clear_dependency_optimization();
        self.clear_loop_optimization();
        self.clear_function_optimization();
        self.clear_debug_stripper();
        self.clear_disable_model_pruning();
        self.clear_scoped_allocator_optimization();
        self.clear_meta_optimizer_iterations();
        self.clear_min_graph_nodes();
        self.clear_memory_optimization();
        self.clear_memory_optimizer_target_node_name_scope();
        self.clear_auto_parallel();
        self.clear_scoped_allocator_opts();
        self.clear_optimizers();
        self.clear_custom_optimizers();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RewriterConfig {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct RewriterConfig_CustomGraphOptimizer {
    // message fields
    pub name: ::std::string::String,
    pub parameter_map: ::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue>,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl RewriterConfig_CustomGraphOptimizer {
    pub fn new() -> RewriterConfig_CustomGraphOptimizer {
        ::std::default::Default::default()
    }

    // string name = 1;

    pub fn clear_name(&mut self) {
        self.name.clear();
    }

    // Param is passed by value, moved
    pub fn set_name(&mut self, v: ::std::string::String) {
        self.name = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_name(&mut self) -> &mut ::std::string::String {
        &mut self.name
    }

    // Take field
    pub fn take_name(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.name, ::std::string::String::new())
    }

    pub fn get_name(&self) -> &str {
        &self.name
    }

    // repeated .tensorflow.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry parameter_map = 2;

    pub fn clear_parameter_map(&mut self) {
        self.parameter_map.clear();
    }

    // Param is passed by value, moved
    pub fn set_parameter_map(&mut self, v: ::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue>) {
        self.parameter_map = v;
    }

    // Mutable pointer to the field.
    pub fn mut_parameter_map(&mut self) -> &mut ::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue> {
        &mut self.parameter_map
    }

    // Take field
    pub fn take_parameter_map(&mut self) -> ::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue> {
        ::std::mem::replace(&mut self.parameter_map, ::std::collections::HashMap::new())
    }

    pub fn get_parameter_map(&self) -> &::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue> {
        &self.parameter_map
    }
}

impl ::protobuf::Message for RewriterConfig_CustomGraphOptimizer {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.name)?;
                },
                2 => {
                    ::protobuf::rt::read_map_into::<::protobuf::types::ProtobufTypeString, ::protobuf::types::ProtobufTypeMessage<super::attr_value::AttrValue>>(wire_type, is, &mut self.parameter_map)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if !self.name.is_empty() {
            my_size += ::protobuf::rt::string_size(1, &self.name);
        }
        my_size += ::protobuf::rt::compute_map_size::<::protobuf::types::ProtobufTypeString, ::protobuf::types::ProtobufTypeMessage<super::attr_value::AttrValue>>(2, &self.parameter_map);
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        if !self.name.is_empty() {
            os.write_string(1, &self.name)?;
        }
        ::protobuf::rt::write_map_with_cached_sizes::<::protobuf::types::ProtobufTypeString, ::protobuf::types::ProtobufTypeMessage<super::attr_value::AttrValue>>(2, &self.parameter_map, os)?;
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RewriterConfig_CustomGraphOptimizer {
        RewriterConfig_CustomGraphOptimizer::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                    "name",
                    |m: &RewriterConfig_CustomGraphOptimizer| { &m.name },
                    |m: &mut RewriterConfig_CustomGraphOptimizer| { &mut m.name },
                ));
                fields.push(::protobuf::reflect::accessor::make_map_accessor::<_, ::protobuf::types::ProtobufTypeString, ::protobuf::types::ProtobufTypeMessage<super::attr_value::AttrValue>>(
                    "parameter_map",
                    |m: &RewriterConfig_CustomGraphOptimizer| { &m.parameter_map },
                    |m: &mut RewriterConfig_CustomGraphOptimizer| { &mut m.parameter_map },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<RewriterConfig_CustomGraphOptimizer>(
                    "RewriterConfig_CustomGraphOptimizer",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static RewriterConfig_CustomGraphOptimizer {
        static mut instance: ::protobuf::lazy::Lazy<RewriterConfig_CustomGraphOptimizer> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const RewriterConfig_CustomGraphOptimizer,
        };
        unsafe {
            instance.get(RewriterConfig_CustomGraphOptimizer::new)
        }
    }
}

impl ::protobuf::Clear for RewriterConfig_CustomGraphOptimizer {
    fn clear(&mut self) {
        self.clear_name();
        self.clear_parameter_map();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RewriterConfig_CustomGraphOptimizer {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_CustomGraphOptimizer {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RewriterConfig_Toggle {
    DEFAULT = 0,
    ON = 1,
    OFF = 2,
    AGGRESSIVE = 3,
}

impl ::protobuf::ProtobufEnum for RewriterConfig_Toggle {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RewriterConfig_Toggle> {
        match value {
            0 => ::std::option::Option::Some(RewriterConfig_Toggle::DEFAULT),
            1 => ::std::option::Option::Some(RewriterConfig_Toggle::ON),
            2 => ::std::option::Option::Some(RewriterConfig_Toggle::OFF),
            3 => ::std::option::Option::Some(RewriterConfig_Toggle::AGGRESSIVE),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RewriterConfig_Toggle] = &[
            RewriterConfig_Toggle::DEFAULT,
            RewriterConfig_Toggle::ON,
            RewriterConfig_Toggle::OFF,
            RewriterConfig_Toggle::AGGRESSIVE,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::EnumDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::EnumDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                ::protobuf::reflect::EnumDescriptor::new("RewriterConfig_Toggle", file_descriptor_proto())
            })
        }
    }
}

impl ::std::marker::Copy for RewriterConfig_Toggle {
}

impl ::std::default::Default for RewriterConfig_Toggle {
    fn default() -> Self {
        RewriterConfig_Toggle::DEFAULT
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_Toggle {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Enum(self.descriptor())
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RewriterConfig_NumIterationsType {
    DEFAULT_NUM_ITERS = 0,
    ONE = 1,
    TWO = 2,
}

impl ::protobuf::ProtobufEnum for RewriterConfig_NumIterationsType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RewriterConfig_NumIterationsType> {
        match value {
            0 => ::std::option::Option::Some(RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS),
            1 => ::std::option::Option::Some(RewriterConfig_NumIterationsType::ONE),
            2 => ::std::option::Option::Some(RewriterConfig_NumIterationsType::TWO),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RewriterConfig_NumIterationsType] = &[
            RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS,
            RewriterConfig_NumIterationsType::ONE,
            RewriterConfig_NumIterationsType::TWO,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::EnumDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::EnumDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                ::protobuf::reflect::EnumDescriptor::new("RewriterConfig_NumIterationsType", file_descriptor_proto())
            })
        }
    }
}

impl ::std::marker::Copy for RewriterConfig_NumIterationsType {
}

impl ::std::default::Default for RewriterConfig_NumIterationsType {
    fn default() -> Self {
        RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_NumIterationsType {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Enum(self.descriptor())
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RewriterConfig_MemOptType {
    DEFAULT_MEM_OPT = 0,
    NO_MEM_OPT = 1,
    MANUAL = 2,
    SWAPPING_HEURISTICS = 4,
    RECOMPUTATION_HEURISTICS = 5,
    SCHEDULING_HEURISTICS = 6,
    HEURISTICS = 3,
}

impl ::protobuf::ProtobufEnum for RewriterConfig_MemOptType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RewriterConfig_MemOptType> {
        match value {
            0 => ::std::option::Option::Some(RewriterConfig_MemOptType::DEFAULT_MEM_OPT),
            1 => ::std::option::Option::Some(RewriterConfig_MemOptType::NO_MEM_OPT),
            2 => ::std::option::Option::Some(RewriterConfig_MemOptType::MANUAL),
            4 => ::std::option::Option::Some(RewriterConfig_MemOptType::SWAPPING_HEURISTICS),
            5 => ::std::option::Option::Some(RewriterConfig_MemOptType::RECOMPUTATION_HEURISTICS),
            6 => ::std::option::Option::Some(RewriterConfig_MemOptType::SCHEDULING_HEURISTICS),
            3 => ::std::option::Option::Some(RewriterConfig_MemOptType::HEURISTICS),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RewriterConfig_MemOptType] = &[
            RewriterConfig_MemOptType::DEFAULT_MEM_OPT,
            RewriterConfig_MemOptType::NO_MEM_OPT,
            RewriterConfig_MemOptType::MANUAL,
            RewriterConfig_MemOptType::SWAPPING_HEURISTICS,
            RewriterConfig_MemOptType::RECOMPUTATION_HEURISTICS,
            RewriterConfig_MemOptType::SCHEDULING_HEURISTICS,
            RewriterConfig_MemOptType::HEURISTICS,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::EnumDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::EnumDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                ::protobuf::reflect::EnumDescriptor::new("RewriterConfig_MemOptType", file_descriptor_proto())
            })
        }
    }
}

impl ::std::marker::Copy for RewriterConfig_MemOptType {
}

impl ::std::default::Default for RewriterConfig_MemOptType {
    fn default() -> Self {
        RewriterConfig_MemOptType::DEFAULT_MEM_OPT
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_MemOptType {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Enum(self.descriptor())
    }
}

static file_descriptor_proto_data: &'static [u8] = b"\
    \n.tensorflow/core/protobuf/rewriter_config.proto\x12\ntensorflow\x1a*te\
    nsorflow/core/framework/attr_value.proto\"P\n\x13AutoParallelOptions\x12\
    \x16\n\x06enable\x18\x01\x20\x01(\x08R\x06enable\x12!\n\x0cnum_replicas\
    \x18\x02\x20\x01(\x05R\x0bnumReplicas\"5\n\x16ScopedAllocatorOptions\x12\
    \x1b\n\tenable_op\x18\x01\x20\x03(\tR\x08enableOp\"\xe5\x0f\n\x0eRewrite\
    rConfig\x12L\n\x10layout_optimizer\x18\x01\x20\x01(\x0e2!.tensorflow.Rew\
    riterConfig.ToggleR\x0flayoutOptimizer\x12L\n\x10constant_folding\x18\
    \x03\x20\x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\x0fconstantFolding\
    \x12P\n\x12shape_optimization\x18\r\x20\x01(\x0e2!.tensorflow.RewriterCo\
    nfig.ToggleR\x11shapeOptimization\x12?\n\tremapping\x18\x0e\x20\x01(\x0e\
    2!.tensorflow.RewriterConfig.ToggleR\tremapping\x12Z\n\x17arithmetic_opt\
    imization\x18\x07\x20\x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\x16ar\
    ithmeticOptimization\x12Z\n\x17dependency_optimization\x18\x08\x20\x01(\
    \x0e2!.tensorflow.RewriterConfig.ToggleR\x16dependencyOptimization\x12N\
    \n\x11loop_optimization\x18\t\x20\x01(\x0e2!.tensorflow.RewriterConfig.T\
    oggleR\x10loopOptimization\x12V\n\x15function_optimization\x18\n\x20\x01\
    (\x0e2!.tensorflow.RewriterConfig.ToggleR\x14functionOptimization\x12H\n\
    \x0edebug_stripper\x18\x0b\x20\x01(\x0e2!.tensorflow.RewriterConfig.Togg\
    leR\rdebugStripper\x122\n\x15disable_model_pruning\x18\x02\x20\x01(\x08R\
    \x13disableModelPruning\x12e\n\x1dscoped_allocator_optimization\x18\x0f\
    \x20\x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\x1bscopedAllocatorOpti\
    mization\x12h\n\x19meta_optimizer_iterations\x18\x0c\x20\x01(\x0e2,.tens\
    orflow.RewriterConfig.NumIterationsTypeR\x17metaOptimizerIterations\x12&\
    \n\x0fmin_graph_nodes\x18\x11\x20\x01(\x05R\rminGraphNodes\x12V\n\x13mem\
    ory_optimization\x18\x04\x20\x01(\x0e2%.tensorflow.RewriterConfig.MemOpt\
    TypeR\x12memoryOptimization\x12S\n'memory_optimizer_target_node_name_sco\
    pe\x18\x06\x20\x01(\tR\"memoryOptimizerTargetNodeNameScope\x12D\n\rauto_\
    parallel\x18\x05\x20\x01(\x0b2\x1f.tensorflow.AutoParallelOptionsR\x0cau\
    toParallel\x12V\n\x15scoped_allocator_opts\x18\x10\x20\x01(\x0b2\".tenso\
    rflow.ScopedAllocatorOptionsR\x13scopedAllocatorOpts\x12\x1e\n\noptimize\
    rs\x18d\x20\x03(\tR\noptimizers\x12]\n\x11custom_optimizers\x18\xc8\x01\
    \x20\x03(\x0b2/.tensorflow.RewriterConfig.CustomGraphOptimizerR\x10custo\
    mOptimizers\x1a\xea\x01\n\x14CustomGraphOptimizer\x12\x12\n\x04name\x18\
    \x01\x20\x01(\tR\x04name\x12f\n\rparameter_map\x18\x02\x20\x03(\x0b2A.te\
    nsorflow.RewriterConfig.CustomGraphOptimizer.ParameterMapEntryR\x0cparam\
    eterMap\x1aV\n\x11ParameterMapEntry\x12\x10\n\x03key\x18\x01\x20\x01(\tR\
    \x03key\x12+\n\x05value\x18\x02\x20\x01(\x0b2\x15.tensorflow.AttrValueR\
    \x05value:\x028\x01\"6\n\x06Toggle\x12\x0b\n\x07DEFAULT\x10\0\x12\x06\n\
    \x02ON\x10\x01\x12\x07\n\x03OFF\x10\x02\x12\x0e\n\nAGGRESSIVE\x10\x03\"<\
    \n\x11NumIterationsType\x12\x15\n\x11DEFAULT_NUM_ITERS\x10\0\x12\x07\n\
    \x03ONE\x10\x01\x12\x07\n\x03TWO\x10\x02\"\x9f\x01\n\nMemOptType\x12\x13\
    \n\x0fDEFAULT_MEM_OPT\x10\0\x12\x0e\n\nNO_MEM_OPT\x10\x01\x12\n\n\x06MAN\
    UAL\x10\x02\x12\x17\n\x13SWAPPING_HEURISTICS\x10\x04\x12\x1c\n\x18RECOMP\
    UTATION_HEURISTICS\x10\x05\x12\x19\n\x15SCHEDULING_HEURISTICS\x10\x06\
    \x12\x0e\n\nHEURISTICS\x10\x03Bs\n\x18org.tensorflow.frameworkB\x14Rewri\
    terConfigProtosP\x01Z<github.com/tensorflow/tensorflow/tensorflow/go/cor\
    e/protobuf\xf8\x01\x01J\xb69\n\x07\x12\x05\0\0\x9b\x01\x01\n\x08\n\x01\
    \x0c\x12\x03\0\0\x12\n\x08\n\x01\x02\x12\x03\x02\x08\x12\n\x08\n\x01\x08\
    \x12\x03\x03\0\x1f\n\x0b\n\x04\x08\xe7\x07\0\x12\x03\x03\0\x1f\n\x0c\n\
    \x05\x08\xe7\x07\0\x02\x12\x03\x03\x07\x17\n\r\n\x06\x08\xe7\x07\0\x02\0\
    \x12\x03\x03\x07\x17\n\x0e\n\x07\x08\xe7\x07\0\x02\0\x01\x12\x03\x03\x07\
    \x17\n\x0c\n\x05\x08\xe7\x07\0\x03\x12\x03\x03\x1a\x1e\n\x08\n\x01\x08\
    \x12\x03\x04\05\n\x0b\n\x04\x08\xe7\x07\x01\x12\x03\x04\05\n\x0c\n\x05\
    \x08\xe7\x07\x01\x02\x12\x03\x04\x07\x1b\n\r\n\x06\x08\xe7\x07\x01\x02\0\
    \x12\x03\x04\x07\x1b\n\x0e\n\x07\x08\xe7\x07\x01\x02\0\x01\x12\x03\x04\
    \x07\x1b\n\x0c\n\x05\x08\xe7\x07\x01\x07\x12\x03\x04\x1e4\n\x08\n\x01\
    \x08\x12\x03\x05\0\"\n\x0b\n\x04\x08\xe7\x07\x02\x12\x03\x05\0\"\n\x0c\n\
    \x05\x08\xe7\x07\x02\x02\x12\x03\x05\x07\x1a\n\r\n\x06\x08\xe7\x07\x02\
    \x02\0\x12\x03\x05\x07\x1a\n\x0e\n\x07\x08\xe7\x07\x02\x02\0\x01\x12\x03\
    \x05\x07\x1a\n\x0c\n\x05\x08\xe7\x07\x02\x03\x12\x03\x05\x1d!\n\x08\n\
    \x01\x08\x12\x03\x06\01\n\x0b\n\x04\x08\xe7\x07\x03\x12\x03\x06\01\n\x0c\
    \n\x05\x08\xe7\x07\x03\x02\x12\x03\x06\x07\x13\n\r\n\x06\x08\xe7\x07\x03\
    \x02\0\x12\x03\x06\x07\x13\n\x0e\n\x07\x08\xe7\x07\x03\x02\0\x01\x12\x03\
    \x06\x07\x13\n\x0c\n\x05\x08\xe7\x07\x03\x07\x12\x03\x06\x160\n\x08\n\
    \x01\x08\x12\x03\x07\0S\n\x0b\n\x04\x08\xe7\x07\x04\x12\x03\x07\0S\n\x0c\
    \n\x05\x08\xe7\x07\x04\x02\x12\x03\x07\x07\x11\n\r\n\x06\x08\xe7\x07\x04\
    \x02\0\x12\x03\x07\x07\x11\n\x0e\n\x07\x08\xe7\x07\x04\x02\0\x01\x12\x03\
    \x07\x07\x11\n\x0c\n\x05\x08\xe7\x07\x04\x07\x12\x03\x07\x14R\n\t\n\x02\
    \x03\0\x12\x03\t\x073\n\n\n\x02\x04\0\x12\x04\x0b\0\x0e\x01\n\n\n\x03\
    \x04\0\x01\x12\x03\x0b\x08\x1b\n\x0b\n\x04\x04\0\x02\0\x12\x03\x0c\x02\
    \x12\n\r\n\x05\x04\0\x02\0\x04\x12\x04\x0c\x02\x0b\x1d\n\x0c\n\x05\x04\0\
    \x02\0\x05\x12\x03\x0c\x02\x06\n\x0c\n\x05\x04\0\x02\0\x01\x12\x03\x0c\
    \x07\r\n\x0c\n\x05\x04\0\x02\0\x03\x12\x03\x0c\x10\x11\n\x0b\n\x04\x04\0\
    \x02\x01\x12\x03\r\x02\x19\n\r\n\x05\x04\0\x02\x01\x04\x12\x04\r\x02\x0c\
    \x12\n\x0c\n\x05\x04\0\x02\x01\x05\x12\x03\r\x02\x07\n\x0c\n\x05\x04\0\
    \x02\x01\x01\x12\x03\r\x08\x14\n\x0c\n\x05\x04\0\x02\x01\x03\x12\x03\r\
    \x17\x18\n\n\n\x02\x04\x01\x12\x04\x10\0\x13\x01\n\n\n\x03\x04\x01\x01\
    \x12\x03\x10\x08\x1e\nC\n\x04\x04\x01\x02\0\x12\x03\x12\x02\x20\x1a6\x20\
    If\x20present,\x20only\x20perform\x20optimization\x20for\x20these\x20ops\
    .\n\n\x0c\n\x05\x04\x01\x02\0\x04\x12\x03\x12\x02\n\n\x0c\n\x05\x04\x01\
    \x02\0\x05\x12\x03\x12\x0b\x11\n\x0c\n\x05\x04\x01\x02\0\x01\x12\x03\x12\
    \x12\x1b\n\x0c\n\x05\x04\x01\x02\0\x03\x12\x03\x12\x1e\x1f\ns\n\x02\x04\
    \x02\x12\x05\x15\0\x9b\x01\x01\"f\x20Graph\x20rewriting\x20is\x20experim\
    ental\x20and\x20subject\x20to\x20change,\x20not\x20covered\x20by\x20any\
    \n\x20API\x20stability\x20guarantees.\n\n\n\n\x03\x04\x02\x01\x12\x03\
    \x15\x08\x16\n\xc6\x01\n\x04\x04\x02\x04\0\x12\x04\x1d\x02%\x032\xb7\x01\
    \x20Configuration\x20options\x20for\x20the\x20meta-optimizer.\x20Unless\
    \x20otherwise\x20noted,\x20these\n\x20configuration\x20options\x20do\x20\
    not\x20apply\x20to\x20explicitly\x20triggered\x20optimization\n\x20passe\
    s\x20in\x20the\x20optimizers\x20field.\n\n\x0c\n\x05\x04\x02\x04\0\x01\
    \x12\x03\x1d\x07\r\n\r\n\x06\x04\x02\x04\0\x02\0\x12\x03\x1e\x04\x10\n\
    \x0e\n\x07\x04\x02\x04\0\x02\0\x01\x12\x03\x1e\x04\x0b\n\x0e\n\x07\x04\
    \x02\x04\0\x02\0\x02\x12\x03\x1e\x0e\x0f\n\r\n\x06\x04\x02\x04\0\x02\x01\
    \x12\x03\x1f\x04\x0b\n\x0e\n\x07\x04\x02\x04\0\x02\x01\x01\x12\x03\x1f\
    \x04\x06\n\x0e\n\x07\x04\x02\x04\0\x02\x01\x02\x12\x03\x1f\t\n\n\r\n\x06\
    \x04\x02\x04\0\x02\x02\x12\x03\x20\x04\x0c\n\x0e\n\x07\x04\x02\x04\0\x02\
    \x02\x01\x12\x03\x20\x04\x07\n\x0e\n\x07\x04\x02\x04\0\x02\x02\x02\x12\
    \x03\x20\n\x0b\n\xaf\x01\n\x06\x04\x02\x04\0\x02\x03\x12\x03$\x04\x13\
    \x1a\x9f\x01\x20Enable\x20some\x20aggressive\x20optimizations\x20that\
    \x20use\x20assumptions\x20that\x20TF\x20graphs\n\x20may\x20break.\x20For\
    \x20example,\x20assume\x20the\x20shape\x20of\x20a\x20placeholder\x20matc\
    hes\x20its\n\x20actual\x20feed.\n\n\x0e\n\x07\x04\x02\x04\0\x02\x03\x01\
    \x12\x03$\x04\x0e\n\x0e\n\x07\x04\x02\x04\0\x02\x03\x02\x12\x03$\x11\x12\
    \ni\n\x04\x04\x02\x04\x01\x12\x04)\x02-\x03\x1a[\x20Enum\x20controlling\
    \x20the\x20number\x20of\x20times\x20to\x20run\x20optimizers.\x20The\x20d\
    efault\x20is\x20to\n\x20run\x20them\x20once.\n\n\x0c\n\x05\x04\x02\x04\
    \x01\x01\x12\x03)\x07\x18\n\r\n\x06\x04\x02\x04\x01\x02\0\x12\x03*\x04\
    \x1a\n\x0e\n\x07\x04\x02\x04\x01\x02\0\x01\x12\x03*\x04\x15\n\x0e\n\x07\
    \x04\x02\x04\x01\x02\0\x02\x12\x03*\x18\x19\n\r\n\x06\x04\x02\x04\x01\
    \x02\x01\x12\x03+\x04\x0c\n\x0e\n\x07\x04\x02\x04\x01\x02\x01\x01\x12\
    \x03+\x04\x07\n\x0e\n\x07\x04\x02\x04\x01\x02\x01\x02\x12\x03+\n\x0b\n\r\
    \n\x06\x04\x02\x04\x01\x02\x02\x12\x03,\x04\x0c\n\x0e\n\x07\x04\x02\x04\
    \x01\x02\x02\x01\x12\x03,\x04\x07\n\x0e\n\x07\x04\x02\x04\x01\x02\x02\
    \x02\x12\x03,\n\x0b\nu\n\x04\x04\x02\x02\0\x12\x031\x02\x1e\x1ah\x20Opti\
    mize\x20tensor\x20layouts\x20(default\x20is\x20ON)\n\x20e.g.\x20This\x20\
    will\x20try\x20to\x20use\x20NCHW\x20layout\x20on\x20GPU\x20which\x20is\
    \x20faster.\n\n\r\n\x05\x04\x02\x02\0\x04\x12\x041\x02-\x03\n\x0c\n\x05\
    \x04\x02\x02\0\x06\x12\x031\x02\x08\n\x0c\n\x05\x04\x02\x02\0\x01\x12\
    \x031\t\x19\n\x0c\n\x05\x04\x02\x02\0\x03\x12\x031\x1c\x1d\n\x91\x01\n\
    \x04\x04\x02\x02\x01\x12\x035\x02\x1e\x1a\x83\x01\x20Fold\x20constants\
    \x20(default\x20is\x20ON)\n\x20Statically\x20infer\x20the\x20value\x20of\
    \x20tensors\x20when\x20possible,\x20and\x20materialize\x20the\n\x20resul\
    t\x20using\x20constants.\n\n\r\n\x05\x04\x02\x02\x01\x04\x12\x045\x021\
    \x1e\n\x0c\n\x05\x04\x02\x02\x01\x06\x12\x035\x02\x08\n\x0c\n\x05\x04\
    \x02\x02\x01\x01\x12\x035\t\x19\n\x0c\n\x05\x04\x02\x02\x01\x03\x12\x035\
    \x1c\x1d\nY\n\x04\x04\x02\x02\x02\x12\x038\x02!\x1aL\x20Shape\x20optimiz\
    ations\x20(default\x20is\x20ON)\n\x20Simplify\x20computations\x20made\
    \x20on\x20shapes.\n\n\r\n\x05\x04\x02\x02\x02\x04\x12\x048\x025\x1e\n\
    \x0c\n\x05\x04\x02\x02\x02\x06\x12\x038\x02\x08\n\x0c\n\x05\x04\x02\x02\
    \x02\x01\x12\x038\t\x1b\n\x0c\n\x05\x04\x02\x02\x02\x03\x12\x038\x1e\x20\
    \n^\n\x04\x04\x02\x02\x03\x12\x03;\x02\x18\x1aQ\x20Remapping\x20(default\
    \x20is\x20ON)\n\x20Remap\x20subgraphs\x20onto\x20more\x20efficient\x20im\
    plementations.\n\n\r\n\x05\x04\x02\x02\x03\x04\x12\x04;\x028!\n\x0c\n\
    \x05\x04\x02\x02\x03\x06\x12\x03;\x02\x08\n\x0c\n\x05\x04\x02\x02\x03\
    \x01\x12\x03;\t\x12\n\x0c\n\x05\x04\x02\x02\x03\x03\x12\x03;\x15\x17\n\
    \x82\x01\n\x04\x04\x02\x02\x04\x12\x03>\x02%\x1au\x20Arithmetic\x20optim\
    izations\x20(default\x20is\x20ON)\n\x20e.g.\x20Simplify\x20arithmetic\
    \x20ops;\x20merge\x20ops\x20with\x20same\x20value\x20(like\x20constants)\
    .\n\n\r\n\x05\x04\x02\x02\x04\x04\x12\x04>\x02;\x18\n\x0c\n\x05\x04\x02\
    \x02\x04\x06\x12\x03>\x02\x08\n\x0c\n\x05\x04\x02\x02\x04\x01\x12\x03>\t\
    \x20\n\x0c\n\x05\x04\x02\x02\x04\x03\x12\x03>#$\n\x8e\x01\n\x04\x04\x02\
    \x02\x05\x12\x03A\x02%\x1a\x80\x01\x20Control\x20dependency\x20optimizat\
    ions\x20(default\x20is\x20ON).\n\x20Remove\x20redundant\x20control\x20de\
    pendencies,\x20which\x20may\x20enable\x20other\x20optimization.\n\n\r\n\
    \x05\x04\x02\x02\x05\x04\x12\x04A\x02>%\n\x0c\n\x05\x04\x02\x02\x05\x06\
    \x12\x03A\x02\x08\n\x0c\n\x05\x04\x02\x02\x05\x01\x12\x03A\t\x20\n\x0c\n\
    \x05\x04\x02\x02\x05\x03\x12\x03A#$\n2\n\x04\x04\x02\x02\x06\x12\x03C\
    \x02\x1f\x1a%\x20Loop\x20optimizations\x20(default\x20is\x20ON).\n\n\r\n\
    \x05\x04\x02\x02\x06\x04\x12\x04C\x02A%\n\x0c\n\x05\x04\x02\x02\x06\x06\
    \x12\x03C\x02\x08\n\x0c\n\x05\x04\x02\x02\x06\x01\x12\x03C\t\x1a\n\x0c\n\
    \x05\x04\x02\x02\x06\x03\x12\x03C\x1d\x1e\n6\n\x04\x04\x02\x02\x07\x12\
    \x03E\x02$\x1a)\x20Function\x20optimizations\x20(default\x20is\x20ON).\n\
    \n\r\n\x05\x04\x02\x02\x07\x04\x12\x04E\x02C\x1f\n\x0c\n\x05\x04\x02\x02\
    \x07\x06\x12\x03E\x02\x08\n\x0c\n\x05\x04\x02\x02\x07\x01\x12\x03E\t\x1e\
    \n\x0c\n\x05\x04\x02\x02\x07\x03\x12\x03E!#\nJ\n\x04\x04\x02\x02\x08\x12\
    \x03G\x02\x1d\x1a=\x20Strips\x20debug-related\x20nodes\x20from\x20the\
    \x20graph\x20(off\x20by\x20default).\n\n\r\n\x05\x04\x02\x02\x08\x04\x12\
    \x04G\x02E$\n\x0c\n\x05\x04\x02\x02\x08\x06\x12\x03G\x02\x08\n\x0c\n\x05\
    \x04\x02\x02\x08\x01\x12\x03G\t\x17\n\x0c\n\x05\x04\x02\x02\x08\x03\x12\
    \x03G\x1a\x1c\nC\n\x04\x04\x02\x02\t\x12\x03I\x02!\x1a6\x20If\x20true,\
    \x20don't\x20remove\x20unnecessary\x20ops\x20from\x20the\x20graph\n\n\r\
    \n\x05\x04\x02\x02\t\x04\x12\x04I\x02G\x1d\n\x0c\n\x05\x04\x02\x02\t\x05\
    \x12\x03I\x02\x06\n\x0c\n\x05\x04\x02\x02\t\x01\x12\x03I\x07\x1c\n\x0c\n\
    \x05\x04\x02\x02\t\x03\x12\x03I\x1f\x20\n\x88\x01\n\x04\x04\x02\x02\n\
    \x12\x03L\x02,\x1a{\x20Try\x20to\x20allocate\x20some\x20independent\x20O\
    p\x20outputs\x20contiguously\x20in\x20order\x20to\n\x20merge\x20or\x20el\
    iminate\x20downstream\x20Ops\x20(off\x20by\x20default).\n\n\r\n\x05\x04\
    \x02\x02\n\x04\x12\x04L\x02I!\n\x0c\n\x05\x04\x02\x02\n\x06\x12\x03L\x02\
    \x08\n\x0c\n\x05\x04\x02\x02\n\x01\x12\x03L\t&\n\x0c\n\x05\x04\x02\x02\n\
    \x03\x12\x03L)+\nb\n\x04\x04\x02\x02\x0b\x12\x03P\x023\x1aU\x20Controls\
    \x20how\x20many\x20times\x20we\x20run\x20the\x20optimizers\x20in\x20meta\
    \x20optimizer\x20(default\n\x20is\x20once).\n\n\r\n\x05\x04\x02\x02\x0b\
    \x04\x12\x04P\x02L,\n\x0c\n\x05\x04\x02\x02\x0b\x06\x12\x03P\x02\x13\n\
    \x0c\n\x05\x04\x02\x02\x0b\x01\x12\x03P\x14-\n\x0c\n\x05\x04\x02\x02\x0b\
    \x03\x12\x03P02\n\xc8\x01\n\x04\x04\x02\x02\x0c\x12\x03V\x02\x1d\x1a\xba\
    \x01\x20The\x20minimum\x20number\x20of\x20nodes\x20in\x20a\x20graph\x20t\
    o\x20optimizer.\x20For\x20smaller\x20graphs,\n\x20optimization\x20is\x20\
    skipped.\n\x200\x20means\x20the\x20system\x20picks\x20an\x20appropriate\
    \x20number.\n\x20<\x200\x20means\x20do\x20not\x20skip\x20optimization.\n\
    \n\r\n\x05\x04\x02\x02\x0c\x04\x12\x04V\x02P3\n\x0c\n\x05\x04\x02\x02\
    \x0c\x05\x12\x03V\x02\x07\n\x0c\n\x05\x04\x02\x02\x0c\x01\x12\x03V\x08\
    \x17\n\x0c\n\x05\x04\x02\x02\x0c\x03\x12\x03V\x1a\x1c\n\x0c\n\x04\x04\
    \x02\x04\x02\x12\x04X\x02p\x03\n\x0c\n\x05\x04\x02\x04\x02\x01\x12\x03X\
    \x07\x11\nN\n\x06\x04\x02\x04\x02\x02\0\x12\x03Z\x04\x18\x1a?\x20The\x20\
    default\x20setting\x20(SCHEDULING\x20and\x20SWAPPING\x20HEURISTICS\x20on\
    ly)\n\n\x0e\n\x07\x04\x02\x04\x02\x02\0\x01\x12\x03Z\x04\x13\n\x0e\n\x07\
    \x04\x02\x04\x02\x02\0\x02\x12\x03Z\x16\x17\n0\n\x06\x04\x02\x04\x02\x02\
    \x01\x12\x03\\\x04\x13\x1a!\x20Disabled\x20in\x20the\x20meta-optimizer.\
    \n\n\x0e\n\x07\x04\x02\x04\x02\x02\x01\x01\x12\x03\\\x04\x0e\n\x0e\n\x07\
    \x04\x02\x04\x02\x02\x01\x02\x12\x03\\\x11\x12\n7\n\x06\x04\x02\x04\x02\
    \x02\x02\x12\x03^\x04\x0f\x1a(\x20Driven\x20by\x20manual\x20op-level\x20\
    annotations.\n\n\x0e\n\x07\x04\x02\x04\x02\x02\x02\x01\x12\x03^\x04\n\n\
    \x0e\n\x07\x04\x02\x04\x02\x02\x02\x02\x12\x03^\r\x0e\n\xfa\x02\n\x06\
    \x04\x02\x04\x02\x02\x03\x12\x03g\x04\x1c\x1az\x20Swapping\x20heuristic\
    \x20will\x20move\x20a\x20tensor\x20from\x20the\x20GPU\x20to\x20the\x20CP\
    U\x20and\x20move\n\x20it\x20back\x20when\x20needed\x20to\x20reduce\x20pe\
    ak\x20memory\x20usage.\n2\xee\x01\x20Driven\x20by\x20heuristics.\x20The\
    \x20behavior\x20of\x20these\x20heuristics\x20is\x20subject\x20to\n\x20ch\
    ange.\x20Currently\x20includes\x20an\x20experimental\x20recomputation\
    \x20and\x20swapping\n\x20heuristics.\x20Manual\x20annotations\x20are\x20\
    respected,\x20but\x20additional\x20nodes\x20are\n\x20selected\x20automat\
    ically.\n\n\x0e\n\x07\x04\x02\x04\x02\x02\x03\x01\x12\x03g\x04\x17\n\x0e\
    \n\x07\x04\x02\x04\x02\x02\x03\x02\x12\x03g\x1a\x1b\n\x9d\x01\n\x06\x04\
    \x02\x04\x02\x02\x04\x12\x03j\x04!\x1a\x8d\x01\x20Recomputation\x20heuri\
    stics\x20will\x20recompute\x20ops\x20(such\x20as\x20Relu\x20activation)\
    \n\x20during\x20backprop\x20instead\x20of\x20storing\x20them,\x20reducin\
    g\x20peak\x20memory\x20usage.\n\n\x0e\n\x07\x04\x02\x04\x02\x02\x04\x01\
    \x12\x03j\x04\x1c\n\x0e\n\x07\x04\x02\x04\x02\x02\x04\x02\x12\x03j\x1f\
    \x20\n\x95\x01\n\x06\x04\x02\x04\x02\x02\x05\x12\x03m\x04\x1e\x1a\x85\
    \x01\x20Scheduling\x20will\x20split\x20big\x20ops\x20such\x20as\x20AddN\
    \x20and\x20try\x20to\x20enforce\x20a\x20schedule\n\x20of\x20the\x20new\
    \x20computations\x20that\x20decreases\x20peak\x20memory\x20usage.\n\n\
    \x0e\n\x07\x04\x02\x04\x02\x02\x05\x01\x12\x03m\x04\x19\n\x0e\n\x07\x04\
    \x02\x04\x02\x02\x05\x02\x12\x03m\x1c\x1d\nN\n\x06\x04\x02\x04\x02\x02\
    \x06\x12\x03o\x04\x13\x1a?\x20Use\x20any\x20combination\x20of\x20swappin\
    g\x20and\x20recomputation\x20heuristics.\n\n\x0e\n\x07\x04\x02\x04\x02\
    \x02\x06\x01\x12\x03o\x04\x0e\n\x0e\n\x07\x04\x02\x04\x02\x02\x06\x02\
    \x12\x03o\x11\x12\n\xab\x01\n\x04\x04\x02\x02\r\x12\x03t\x02%\x1a\x9d\
    \x01\x20Configures\x20memory\x20optimization\x20passes\x20through\x20the\
    \x20meta-optimizer.\x20Has\x20no\n\x20effect\x20on\x20manually\x20reques\
    ted\x20memory\x20optimization\x20passes\x20in\x20the\x20optimizers\n\x20\
    field.\n\n\r\n\x05\x04\x02\x02\r\x04\x12\x04t\x02p\x03\n\x0c\n\x05\x04\
    \x02\x02\r\x06\x12\x03t\x02\x0c\n\x0c\n\x05\x04\x02\x02\r\x01\x12\x03t\r\
    \x20\n\x0c\n\x05\x04\x02\x02\r\x03\x12\x03t#$\n\xbe\x04\n\x04\x04\x02\
    \x02\x0e\x12\x03}\x025\x1a\xb0\x04\x20A\x20node\x20name\x20scope\x20for\
    \x20node\x20names\x20which\x20are\x20valid\x20outputs\x20of\x20recompuat\
    ions.\n\x20Inputs\x20to\x20nodes\x20that\x20match\x20this\x20scope\x20ma\
    y\x20be\x20recomputed\x20(subject\x20either\x20to\n\x20manual\x20annotat\
    ion\x20of\x20those\x20input\x20nodes\x20or\x20to\x20manual\x20annotation\
    \x20and\n\x20heuristics\x20depending\x20on\x20memory_optimization),\x20b\
    ut\x20the\x20nodes\x20themselves\x20will\n\x20not\x20be\x20recomputed.\
    \x20This\x20matches\x20any\x20sub-scopes\x20as\x20well,\x20meaning\x20th\
    e\x20scope\n\x20can\x20appear\x20not\x20just\x20as\x20a\x20top-level\x20\
    scope.\x20For\x20example,\x20if\x20the\x20value\x20is\n\x20\"gradients/\
    \",\x20the\x20default,\x20it\x20will\x20match\x20node\x20name\x20\"gradi\
    ents/foo\",\n\x20\"foo/gradients/bar\",\x20but\x20not\x20\"foo_gradients\
    /\"\n\n\r\n\x05\x04\x02\x02\x0e\x04\x12\x04}\x02t%\n\x0c\n\x05\x04\x02\
    \x02\x0e\x05\x12\x03}\x02\x08\n\x0c\n\x05\x04\x02\x02\x0e\x01\x12\x03}\t\
    0\n\x0c\n\x05\x04\x02\x02\x0e\x03\x12\x03}34\n\x98\x01\n\x04\x04\x02\x02\
    \x0f\x12\x04\x81\x01\x02(\x1a\x89\x01\x20Configures\x20AutoParallel\x20o\
    ptimization\x20passes\x20either\x20through\x20the\n\x20meta-optimizer\
    \x20or\x20when\x20manually\x20specified\x20through\x20the\x20optimizers\
    \x20field.\n\n\x0e\n\x05\x04\x02\x02\x0f\x04\x12\x05\x81\x01\x02}5\n\r\n\
    \x05\x04\x02\x02\x0f\x06\x12\x04\x81\x01\x02\x15\n\r\n\x05\x04\x02\x02\
    \x0f\x01\x12\x04\x81\x01\x16#\n\r\n\x05\x04\x02\x02\x0f\x03\x12\x04\x81\
    \x01&'\n\x0c\n\x04\x04\x02\x02\x10\x12\x04\x83\x01\x024\n\x0f\n\x05\x04\
    \x02\x02\x10\x04\x12\x06\x83\x01\x02\x81\x01(\n\r\n\x05\x04\x02\x02\x10\
    \x06\x12\x04\x83\x01\x02\x18\n\r\n\x05\x04\x02\x02\x10\x01\x12\x04\x83\
    \x01\x19.\n\r\n\x05\x04\x02\x02\x10\x03\x12\x04\x83\x0113\n\x85\x05\n\
    \x04\x04\x02\x02\x11\x12\x04\x91\x01\x02#\x1a\xf6\x04\x20If\x20non-empty\
    ,\x20will\x20use\x20this\x20as\x20an\x20alternative\x20way\x20to\x20spec\
    ify\x20a\x20list\x20of\n\x20optimizations\x20to\x20turn\x20on\x20and\x20\
    the\x20order\x20of\x20the\x20optimizations\x20(replacing\x20the\n\x20met\
    a-optimizer).\n\n\x20Of\x20the\x20RewriterConfig\x20options,\x20only\x20\
    the\x20AutoParallel\x20configuration\x20options\n\x20(the\x20auto_parall\
    el\x20field)\x20apply\x20to\x20manually\x20requested\x20optimization\x20\
    passes\n\x20(\"autoparallel\").\x20Memory\x20optimization\x20passes\x20(\
    \"memory\")\x20invoked\x20here\x20are\n\x20not\x20configurable\x20(in\
    \x20contrast\x20to\x20memory\x20optimization\x20passes\x20through\x20the\
    \n\x20meta-optimizer)\x20and\x20act\x20only\x20on\x20manual\x20op\x20ann\
    otations.\n\n\x20Custom\x20registered\x20optimizers\x20will\x20be\x20run\
    \x20after\x20the\x20base\x20optimizers,\x20in\n\x20the\x20order\x20that\
    \x20they\x20are\x20specified.\n\n\r\n\x05\x04\x02\x02\x11\x04\x12\x04\
    \x91\x01\x02\n\n\r\n\x05\x04\x02\x02\x11\x05\x12\x04\x91\x01\x0b\x11\n\r\
    \n\x05\x04\x02\x02\x11\x01\x12\x04\x91\x01\x12\x1c\n\r\n\x05\x04\x02\x02\
    \x11\x03\x12\x04\x91\x01\x1f\"\nO\n\x04\x04\x02\x03\0\x12\x06\x94\x01\
    \x02\x97\x01\x03\x1a?\x20Message\x20to\x20describe\x20custom\x20graph\
    \x20optimizer\x20and\x20its\x20parameters\n\n\r\n\x05\x04\x02\x03\0\x01\
    \x12\x04\x94\x01\n\x1e\n\x0e\n\x06\x04\x02\x03\0\x02\0\x12\x04\x95\x01\
    \x04\x14\n\x11\n\x07\x04\x02\x03\0\x02\0\x04\x12\x06\x95\x01\x04\x94\x01\
    \x20\n\x0f\n\x07\x04\x02\x03\0\x02\0\x05\x12\x04\x95\x01\x04\n\n\x0f\n\
    \x07\x04\x02\x03\0\x02\0\x01\x12\x04\x95\x01\x0b\x0f\n\x0f\n\x07\x04\x02\
    \x03\0\x02\0\x03\x12\x04\x95\x01\x12\x13\n\x0e\n\x06\x04\x02\x03\0\x02\
    \x01\x12\x04\x96\x01\x04-\n\x11\n\x07\x04\x02\x03\0\x02\x01\x04\x12\x06\
    \x96\x01\x04\x95\x01\x14\n\x0f\n\x07\x04\x02\x03\0\x02\x01\x06\x12\x04\
    \x96\x01\x04\x1a\n\x0f\n\x07\x04\x02\x03\0\x02\x01\x01\x12\x04\x96\x01\
    \x1b(\n\x0f\n\x07\x04\x02\x03\0\x02\x01\x03\x12\x04\x96\x01+,\n7\n\x04\
    \x04\x02\x02\x12\x12\x04\x9a\x01\x028\x1a)\x20list\x20of\x20CustomGraphO\
    ptimizers\x20to\x20apply.\n\n\r\n\x05\x04\x02\x02\x12\x04\x12\x04\x9a\
    \x01\x02\n\n\r\n\x05\x04\x02\x02\x12\x06\x12\x04\x9a\x01\x0b\x1f\n\r\n\
    \x05\x04\x02\x02\x12\x01\x12\x04\x9a\x01\x201\n\r\n\x05\x04\x02\x02\x12\
    \x03\x12\x04\x9a\x0147b\x06proto3\
";

static mut file_descriptor_proto_lazy: ::protobuf::lazy::Lazy<::protobuf::descriptor::FileDescriptorProto> = ::protobuf::lazy::Lazy {
    lock: ::protobuf::lazy::ONCE_INIT,
    ptr: 0 as *const ::protobuf::descriptor::FileDescriptorProto,
};

fn parse_descriptor_proto() -> ::protobuf::descriptor::FileDescriptorProto {
    ::protobuf::parse_from_bytes(file_descriptor_proto_data).unwrap()
}

pub fn file_descriptor_proto() -> &'static ::protobuf::descriptor::FileDescriptorProto {
    unsafe {
        file_descriptor_proto_lazy.get(|| {
            parse_descriptor_proto()
        })
    }
}
